{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages to be Upgraded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install with Conda\n",
    "conda install -c conda-forge pyarrow\n",
    "\n",
    "# Install PyArrow with Python\n",
    "pip install pyarrow==0.15.0\n",
    "\n",
    "# Install Py4j with Python\n",
    "pip install py4j==0.10.9\n",
    "\n",
    "# Install pyspark with Python\n",
    "pip install pyspark==3.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PandasUDF_with_PyArrow\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.fallback.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.parquet.mergeSchema\", \"false\") \\\n",
    "    .config(\"spark.hadoop.parquet.enable.summary-metadata\", \"false\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://W007.corp.commencis.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PandasUDF_with_PyArrow</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1b6d7ee7108>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Session Details\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session All Assigned Configurations \n",
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet to Arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing PyArrow Parquet\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Link to data: \n",
    "# https://www.kaggle.com/yassinealouini/m5-sales-hierarchy-dataset\n",
    "\n",
    "path = 'dataset/dimension.parquet'\n",
    "\n",
    "data_frame = pq.read_table(path).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>category</th>\n",
       "      <th>id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>CA</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>CA</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>CA</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>CA</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840006</th>\n",
       "      <td>WI</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>FOODS_3_823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840288</th>\n",
       "      <td>WI</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>FOODS_3_824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840570</th>\n",
       "      <td>WI</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840852</th>\n",
       "      <td>WI</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841000</th>\n",
       "      <td>WI</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        location department category                             id store_id  \\\n",
       "0             CA  HOBBIES_1  HOBBIES  HOBBIES_1_001_CA_1_validation     CA_1   \n",
       "154           CA  HOBBIES_1  HOBBIES  HOBBIES_1_002_CA_1_validation     CA_1   \n",
       "416           CA  HOBBIES_1  HOBBIES  HOBBIES_1_003_CA_1_validation     CA_1   \n",
       "541           CA  HOBBIES_1  HOBBIES  HOBBIES_1_004_CA_1_validation     CA_1   \n",
       "818           CA  HOBBIES_1  HOBBIES  HOBBIES_1_005_CA_1_validation     CA_1   \n",
       "...          ...        ...      ...                            ...      ...   \n",
       "6840006       WI    FOODS_3    FOODS    FOODS_3_823_WI_3_validation     WI_3   \n",
       "6840288       WI    FOODS_3    FOODS    FOODS_3_824_WI_3_validation     WI_3   \n",
       "6840570       WI    FOODS_3    FOODS    FOODS_3_825_WI_3_validation     WI_3   \n",
       "6840852       WI    FOODS_3    FOODS    FOODS_3_826_WI_3_validation     WI_3   \n",
       "6841000       WI    FOODS_3    FOODS    FOODS_3_827_WI_3_validation     WI_3   \n",
       "\n",
       "               item_id  \n",
       "0        HOBBIES_1_001  \n",
       "154      HOBBIES_1_002  \n",
       "416      HOBBIES_1_003  \n",
       "541      HOBBIES_1_004  \n",
       "818      HOBBIES_1_005  \n",
       "...                ...  \n",
       "6840006    FOODS_3_823  \n",
       "6840288    FOODS_3_824  \n",
       "6840570    FOODS_3_825  \n",
       "6840852    FOODS_3_826  \n",
       "6841000    FOODS_3_827  \n",
       "\n",
       "[30490 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet to Arrow with Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "pandas_df = pd.DataFrame(data={'column_1': [1, 2], 'column_2': [3, 4], 'column_3': [5, 6]})\n",
    "table = pa.Table.from_pandas(pandas_df, preserve_index=True)\n",
    "pq.write_table(table, 'pandas_dataframe.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_1  column_2  column_3\n",
       "0         1         3         5\n",
       "1         2         4         6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "column_1: int64\n",
       "column_2: int64\n",
       "column_3: int64\n",
       "__index_level_0__: int64\n",
       "metadata\n",
       "--------\n",
       "{b'pandas': b'{\"index_columns\": [\"__index_level_0__\"], \"column_indexes\": [{\"na'\n",
       "            b'me\": null, \"field_name\": null, \"pandas_type\": \"unicode\", \"numpy_'\n",
       "            b'type\": \"object\", \"metadata\": {\"encoding\": \"UTF-8\"}}], \"columns\":'\n",
       "            b' [{\"name\": \"column_1\", \"field_name\": \"column_1\", \"pandas_type\": '\n",
       "            b'\"int64\", \"numpy_type\": \"int64\", \"metadata\": null}, {\"name\": \"col'\n",
       "            b'umn_2\", \"field_name\": \"column_2\", \"pandas_type\": \"int64\", \"numpy'\n",
       "            b'_type\": \"int64\", \"metadata\": null}, {\"name\": \"column_3\", \"field_'\n",
       "            b'name\": \"column_3\", \"pandas_type\": \"int64\", \"numpy_type\": \"int64\"'\n",
       "            b', \"metadata\": null}, {\"name\": null, \"field_name\": \"__index_level'\n",
       "            b'_0__\", \"pandas_type\": \"int64\", \"numpy_type\": \"int64\", \"metadata\"'\n",
       "            b': null}], \"creator\": {\"library\": \"pyarrow\", \"version\": \"0.15.1\"}'\n",
       "            b', \"pandas_version\": \"1.0.1\"}'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Script Processing Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.390625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "# Processor Time\n",
    "time.process_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192.0849444"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wall-Clock Time\n",
    "time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1596023702.1228762"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543412.968"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.monotonic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Pandas UDFs (Vectorized UDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SCALAR Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|weight_avg_udf(weight)|\n",
      "+----------------------+\n",
      "|                    15|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql import Window\n",
    "\n",
    "dataframe = spark.createDataFrame(\n",
    "    [(1, 5), (2, 7), (2, 8), (2, 10), (3, 18), (3, 22), (4, 36)],\n",
    "    (\"index\", \"weight\"))\n",
    "\n",
    "# The function definition and the UDF creation\n",
    "@pandas_udf(\"int\")\n",
    "def weight_avg_udf(weight: pd.Series) -> float:\n",
    "    return weight.mean()\n",
    "\n",
    "dataframe.select(weight_avg_udf(dataframe['weight'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. GROUPED_AGG Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------+\n",
      "|index|weight_avg_udf(weight)|\n",
      "+-----+----------------------+\n",
      "|    1|                     5|\n",
      "|    3|                    20|\n",
      "|    2|                     8|\n",
      "|    4|                    36|\n",
      "+-----+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregation Process on Pandas UDF\n",
    "dataframe.groupby(\"index\").agg(weight_avg_udf(dataframe['weight'])).show()\n",
    "\n",
    "w = Window \\\n",
    "    .partitionBy('index') \\\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+\n",
      "|index|weight|avg_weight|\n",
      "+-----+------+----------+\n",
      "|    1|     5|         5|\n",
      "|    3|    18|        20|\n",
      "|    3|    22|        20|\n",
      "|    2|     7|         8|\n",
      "|    2|     8|         8|\n",
      "|    2|    10|         8|\n",
      "|    4|    36|        36|\n",
      "+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the windowed results\n",
    "dataframe.withColumn('avg_weight', weight_avg_udf(dataframe['weight']).over(w)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GROUPED_MAP Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|index|weight|\n",
      "+-----+------+\n",
      "|    1|     0|\n",
      "|    3|    -2|\n",
      "|    3|     2|\n",
      "|    2|    -1|\n",
      "|    2|     0|\n",
      "|    2|     1|\n",
      "|    4|     0|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Pandas DataFrame generation\n",
    "pandas_dataframe = pd.DataFrame(np.random.rand(200, 4))\n",
    "\n",
    "def weight_map_udf(pandas_dataframe):\n",
    "    weight = pandas_dataframe.weight\n",
    "    return pandas_dataframe.assign(weight=weight - weight.mean())\n",
    "\n",
    "dataframe.groupby(\"index\").applyInPandas(weight_map_udf, schema=\"index int, weight int\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
